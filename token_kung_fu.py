# Bu·ªïi t·ªëi Ng√†y 1: Gi·∫£i m√£ "H·ªôp ƒëen" Tokenization
# =============================================
# LLM kh√¥ng hi·ªÉu "T·ª´" - ch√∫ng x·ª≠ l√Ω c√°c chu·ªói s·ªë (tokens)
# Token c√≥ th·ªÉ l√†: m·ªôt t·ª´, m·ªôt ph·∫ßn c·ªßa t·ª´, ho·∫∑c d·∫•u c√°ch

import tiktoken

def token_kung_fu(text):
    """
    Ph√¢n t√≠ch c√°ch LLM "nh√¨n" vƒÉn b·∫£n th√¥ng qua tokenization.
    S·ª≠ d·ª•ng encoding c·ªßa model gpt-4o (t∆∞∆°ng th√≠ch Azure OpenAI)
    """
    # S·ª≠ d·ª•ng encoding c·ªßa model gpt-4o
    encoding = tiktoken.encoding_for_model("gpt-4o")
    
    # M√£ h√≥a vƒÉn b·∫£n th√†nh list c√°c token IDs
    tokens = encoding.encode(text)
    
    print(f"\n{'='*50}")
    print(f"üìù VƒÉn b·∫£n: '{text}'")
    print(f"üìä S·ªë l∆∞·ª£ng token: {len(tokens)}")
    print(f"üî¢ Token IDs: {tokens}")
    print(f"\nüîç Chi ti·∫øt t·ª´ng token:")
    
    # Gi·∫£i m√£ t·ª´ng ID ƒë·ªÉ th·∫•y LLM th·ª±c s·ª± "nh√¨n" g√¨
    for i, token_id in enumerate(tokens):
        decoded = encoding.decode([token_id])
        print(f"   [{i+1}] ID {token_id:6d} -> '{decoded}'")
    
    return tokens

def demo_why_llm_bad_at_math():
    """
    Demo: T·∫°i sao LLM th∆∞·ªùng t√≠nh to√°n sai?
    V√¨ c√°c con s·ªë b·ªã chia c·∫Øt th√†nh c√°c token kh√¥ng logic
    """
    print("\n" + "="*50)
    print("üßÆ DEMO: T·∫†I SAO LLM K√âM TO√ÅN?")
    print("="*50)
    
    encoding = tiktoken.encoding_for_model("gpt-4o")
    
    numbers = ["12345", "123456789", "1000000"]
    for num in numbers:
        tokens = encoding.encode(num)
        print(f"\nS·ªë '{num}':")
        print(f"  ‚Üí B·ªã chia th√†nh {len(tokens)} tokens: ", end="")
        for token_id in tokens:
            print(f"'{encoding.decode([token_id])}'", end=" ")
        print()

def demo_strawberry_problem():
    """
    Demo: T·∫°i sao LLM kh√¥ng ƒë·∫øm ƒë∆∞·ª£c ch·ªØ 'r' trong 'strawberry'?
    V√¨ tokenizer chia t·ª´ th√†nh c√°c m·∫£nh, kh√¥ng ph·∫£i t·ª´ng ch·ªØ c√°i
    """
    print("\n" + "="*50)
    print("üçì DEMO: V·∫§N ƒê·ªÄ 'STRAWBERRY'")
    print("="*50)
    
    encoding = tiktoken.encoding_for_model("gpt-4o")
    
    word = "strawberry"
    tokens = encoding.encode(word)
    
    print(f"\nT·ª´ '{word}' ƒë∆∞·ª£c LLM nh√¨n nh∆∞ th·∫ø n√†o?")
    print(f"‚Üí B·ªã chia th√†nh {len(tokens)} tokens:")
    
    for i, token_id in enumerate(tokens):
        decoded = encoding.decode([token_id])
        r_count = decoded.count('r')
        print(f"   Token {i+1}: '{decoded}' (ch·ª©a {r_count} ch·ªØ 'r')")
    
    print(f"\nüí° K·∫øt lu·∫≠n:")
    print(f"   LLM KH√îNG nh√¨n t·ª´ng ch·ªØ c√°i 'r' ri√™ng l·∫ª!")
    print(f"   N√≥ ch·ªâ th·∫•y c√°c token, n√™n ƒë·∫øm sai l√† ƒëi·ªÅu d·ªÖ hi·ªÉu.")

def demo_cost_calculation():
    """
    Demo: T√≠nh chi ph√≠ d·ª±a tr√™n token (kh√¥ng ph·∫£i t·ª´ hay k√Ω t·ª±)
    """
    print("\n" + "="*50)
    print("üí∞ DEMO: T√çNH CHI PH√ç API")
    print("="*50)
    
    encoding = tiktoken.encoding_for_model("gpt-4o")
    
    texts = [
        "Hello",
        "Xin ch√†o",
        "L·∫≠p tr√¨nh AI v·ªõi Python",
        "The quick brown fox jumps over the lazy dog"
    ]
    
    # Gi√° ∆∞·ªõc t√≠nh cho GPT-4o (input)
    price_per_1k_tokens = 0.005  # $0.005 per 1K tokens
    
    print(f"\nGi√°: ${price_per_1k_tokens} / 1000 tokens")
    print("-" * 50)
    
    for text in texts:
        tokens = encoding.encode(text)
        char_count = len(text)
        word_count = len(text.split())
        token_count = len(tokens)
        cost = (token_count / 1000) * price_per_1k_tokens
        
        print(f"\n'{text}'")
        print(f"   K√Ω t·ª±: {char_count}, T·ª´: {word_count}, Token: {token_count}")
        print(f"   Chi ph√≠: ${cost:.6f}")

# ===== CH·∫†Y T·∫§T C·∫¢ DEMO =====
if __name__ == "__main__":
    print("ü•ã TOKEN KUNG FU - Gi·∫£i m√£ Tokenization")
    print("="*50)
    
    # B√†i t·∫≠p c∆° b·∫£n
    token_kung_fu("Apple")
    token_kung_fu("apple")
    token_kung_fu("L·∫≠p tr√¨nh AI")
    token_kung_fu("Hello, how are you?")
    
    # Demo c√°c v·∫•n ƒë·ªÅ th·ª±c t·∫ø
    demo_why_llm_bad_at_math()
    demo_strawberry_problem()
    demo_cost_calculation()
    
    # K·∫øt lu·∫≠n
    print("\n" + "="*50)
    print("üìö K·∫æT LU·∫¨N - T·∫°i sao Tokenization quan tr·ªçng?")
    print("="*50)
    print("""
    1. LLM kh√¥ng hi·ªÉu t·ª´/ch·ªØ c√°i - ch·ªâ hi·ªÉu TOKEN
    2. Token = m·∫£nh vƒÉn b·∫£n c√≥ th·ªÉ l√† t·ª´, ph·∫ßn t·ª´, ho·∫∑c d·∫•u c√°ch
    3. Gi·∫£i th√≠ch ƒë∆∞·ª£c t·∫°i sao LLM:
       - K√©m to√°n (s·ªë b·ªã chia c·∫Øt kh√¥ng logic)
       - Kh√¥ng ƒë·∫øm ƒë∆∞·ª£c ch·ªØ c√°i (nh√¨n token, kh√¥ng ph·∫£i letter)
       - T√≠nh ti·ªÅn theo token (kh√¥ng ph·∫£i t·ª´/k√Ω t·ª±)
    """)
