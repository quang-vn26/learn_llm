# ğŸ“ Learn AI - Ã”n táº­p kiáº¿n thá»©c

## ğŸ¤– LLM & Transformer CÆ¡ báº£n

### â“ CÃ¢u 1: LLM viáº¿t táº¯t cá»§a tá»« gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**LLM = Large Language Model** (MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n)

| ThÃ nh pháº§n | Ã nghÄ©a |
|------------|---------|
| **Large** | Lá»›n - hÃ ng tá»· tham sá»‘ (parameters), Ä‘Æ°á»£c train trÃªn lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“ |
| **Language** | NgÃ´n ngá»¯ - hiá»ƒu vÃ  sinh ra vÄƒn báº£n cá»§a con ngÆ°á»i |
| **Model** | MÃ´ hÃ¬nh - thuáº­t toÃ¡n AI Ä‘Æ°á»£c huáº¥n luyá»‡n |

**VÃ­ dá»¥ cÃ¡c LLM phá»• biáº¿n:**
- GPT-4, GPT-4o (OpenAI)
- Claude 3.5 Sonnet (Anthropic)
- Gemini 1.5, Gemini 2.0 (Google)
- Llama 3 (Meta)

**LLM lÃ m Ä‘Æ°á»£c gÃ¬?**
- Tráº£ lá»i cÃ¢u há»i, viáº¿t vÄƒn báº£n
- Dá»‹ch thuáº­t, tÃ³m táº¯t
- Viáº¿t code, sá»­a lá»—i
- PhÃ¢n tÃ­ch dá»¯ liá»‡u

</details>

---

### â“ CÃ¢u 2: CÆ¡ cháº¿ chÃ­nh cá»§a Transformer lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Self-Attention** (CÆ¡ cháº¿ Tá»± ChÃº Ã) lÃ  trÃ¡i tim cá»§a kiáº¿n trÃºc Transformer!

**Self-Attention lÃ  gÃ¬?**

NÃ³ cho phÃ©p má»—i tá»« trong cÃ¢u "nhÃ¬n" vÃ  "chÃº Ã½" Ä‘áº¿n táº¥t cáº£ cÃ¡c tá»« khÃ¡c Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh.

**VÃ­ dá»¥ minh há»a:**

```
CÃ¢u: "Con mÃ¨o Ä‘uá»•i con chuá»™t vÃ¬ nÃ³ Ä‘Ã³i"
                                  â†“
                          "nÃ³" chá»‰ ai?
```

Self-Attention giÃºp model hiá»ƒu Ä‘Æ°á»£c "nÃ³" chá»‰ **"con mÃ¨o"** (vÃ¬ mÃ¨o má»›i Ä‘Ã³i vÃ  Ä‘uá»•i chuá»™t).

**CÃ¡ch hoáº¡t Ä‘á»™ng Ä‘Æ¡n giáº£n:**

```
BÆ°á»›c 1: Má»—i tá»« táº¡o ra 3 vector: Query (Q), Key (K), Value (V)
BÆ°á»›c 2: TÃ­nh Ä‘á»™ "liÃªn quan" giá»¯a cÃ¡c tá»«: Q Ã— K
BÆ°á»›c 3: DÃ¹ng Ä‘á»™ liÃªn quan lÃ m trá»ng sá»‘ Ä‘á»ƒ káº¿t há»£p cÃ¡c Value
```

| Tá»« | ChÃº Ã½ nhiá»u Ä‘áº¿n | LÃ½ do |
|----|-----------------|-------|
| "nÃ³" | "mÃ¨o" (80%), "chuá»™t" (15%) | Ngá»¯ cáº£nh "Ä‘uá»•i" vÃ  "Ä‘Ã³i" |
| "Ä‘uá»•i" | "mÃ¨o" (70%), "chuá»™t" (25%) | MÃ¨o lÃ  chá»§ thá»ƒ hÃ nh Ä‘á»™ng |

**Táº¡i sao Self-Attention máº¡nh?**
- Hiá»ƒu Ä‘Æ°á»£c ngá»¯ cáº£nh xa (khÃ´ng giá»›i háº¡n khoáº£ng cÃ¡ch tá»«)
- Xá»­ lÃ½ song song (nhanh hÆ¡n RNN/LSTM)
- Linh hoáº¡t vá»›i nhiá»u loáº¡i quan há»‡

</details>

---

### â“ CÃ¢u 3: Tokenization lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Tokenization** lÃ  quÃ¡ trÃ¬nh **chia vÄƒn báº£n thÃ nh cÃ¡c máº£nh nhá» (tokens)** Ä‘á»ƒ LLM cÃ³ thá»ƒ xá»­ lÃ½.

**Táº¡i sao cáº§n Tokenization?**

LLM khÃ´ng thá»ƒ Ä‘á»c text trá»±c tiáº¿p! NÃ³ cáº§n chuyá»ƒn text â†’ sá»‘ (token IDs).

```
"Hello World" â†’ [15496, 2159] â†’ LLM xá»­ lÃ½ â†’ [Output IDs] â†’ "Xin chÃ o"
```

**VÃ­ dá»¥ Tokenization thá»±c táº¿:**

| VÄƒn báº£n | Tokens | Sá»‘ lÆ°á»£ng |
|---------|--------|----------|
| `"Hello"` | `["Hello"]` | 1 token |
| `"Hello World"` | `["Hello", " World"]` | 2 tokens |
| `"Xin chÃ o"` | `["X", "in", " ch", "Ã o"]` | 4 tokens |
| `"GPT-4"` | `["G", "PT", "-", "4"]` | 4 tokens |
| `"strawberry"` | `["st", "raw", "berry"]` | 3 tokens |

**Quy luáº­t tokenization:**
```python
# Tá»« phá»• biáº¿n â†’ Ã­t tokens
"the"        â†’ ["the"]           # 1 token
"computer"   â†’ ["computer"]       # 1 token

# Tá»« hiáº¿m hoáº·c tiáº¿ng Viá»‡t â†’ nhiá»u tokens hÆ¡n
"Viá»‡t Nam"   â†’ ["Vi", "á»‡t", " Nam"]  # 3 tokens
"Láº­p trÃ¬nh"  â†’ ["L", "áº­p", " tr", "Ã¬nh"]  # 4 tokens
```

**Code demo:**
```python
import tiktoken

encoder = tiktoken.encoding_for_model("gpt-4")

text = "Xin chÃ o Viá»‡t Nam!"
tokens = encoder.encode(text)

print(f"Text: {text}")
print(f"Token IDs: {tokens}")
print(f"Sá»‘ tokens: {len(tokens)}")

# Xem tá»«ng token lÃ  gÃ¬
for token_id in tokens:
    print(f"  {token_id} â†’ '{encoder.decode([token_id])}'")
```

**Output:**
```
Text: Xin chÃ o Viá»‡t Nam!
Token IDs: [55, 258, 559, 3975, 79136, 23561, 0]
Sá»‘ tokens: 7
  55 â†’ 'X'
  258 â†’ 'in'
  559 â†’ ' ch'
  3975 â†’ 'Ã o'
  79136 â†’ ' Vi'
  23561 â†’ 'á»‡t'
  ...
```

**ğŸ’¡ Ghi nhá»›:** Tiáº¿ng Viá»‡t tá»‘n nhiá»u tokens hÆ¡n tiáº¿ng Anh â†’ chi phÃ­ API cao hÆ¡n!

</details>

---

## ğŸ“š Python Async/Await

### â“ CÃ¢u 4: Sá»± khÃ¡c biá»‡t giá»¯a Sync vÃ  Async lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Äá»“ng bá»™ (Sync)** - Cháº¡y tuáº§n tá»±, pháº£i Ä‘á»£i task trÆ°á»›c xong má»›i cháº¡y task sau:
```
Request 1 â”€â”€â”€â”€> (3s) â”€â”€â”€â”€> Xong
                           Request 2 â”€â”€â”€â”€> (4s) â”€â”€â”€â”€> Xong
                                                      Request 3 â”€â”€â”€â”€> (5s) â”€â”€â”€â”€> Xong
Tá»•ng: 12 giÃ¢y
```

**Báº¥t Ä‘á»“ng bá»™ (Async)** - Cháº¡y song song, táº¥t cáº£ task cháº¡y cÃ¹ng lÃºc:
```
Request 1 â”€â”€â”€â”€> (3s) â”€â”€â”€â”€> Xong
Request 2 â”€â”€â”€â”€> (4s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Xong
Request 3 â”€â”€â”€â”€> (5s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Xong
Tá»•ng: ~5 giÃ¢y (báº±ng task lÃ¢u nháº¥t)
```

</details>

---

### â“ CÃ¢u 5: Táº¡i sao gá»i hÃ m `async` mÃ  nÃ³ khÃ´ng cháº¡y ngay?

```python
async def say_hello():
    print("Hello!")

result = say_hello()  # Táº¡i sao khÃ´ng in ra "Hello!"?
```

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

Khi Ä‘á»‹nh nghÄ©a hÃ m vá»›i `async def`, Python biáº¿n nÃ³ thÃ nh **coroutine function**.

| Loáº¡i hÃ m | Khi gá»i | Káº¿t quáº£ |
|----------|---------|---------|
| HÃ m thÆ°á»ng `def` | `say_hello()` | **Thá»±c thi ngay** |
| HÃ m async `async def` | `say_hello()` | **KhÃ´ng thá»±c thi**, tráº£ vá» `coroutine object` |

**Coroutine** giá»‘ng nhÆ° **"cÃ´ng thá»©c náº¥u Äƒn"** - báº¡n cÃ³ cÃ´ng thá»©c nhÆ°ng chÆ°a náº¥u!

</details>

---

### â“ CÃ¢u 6: LÃ m sao Ä‘á»ƒ coroutine THá»°C Sá»° cháº¡y?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**CÃ¡ch 1:** DÃ¹ng `await` (bÃªn trong hÃ m async khÃ¡c)
```python
async def main():
    result = await say_hello()  # âœ… CHáº Y vÃ  Ä‘á»£i káº¿t quáº£
```

**CÃ¡ch 2:** DÃ¹ng `asyncio.run()` hoáº·c `asyncio.gather()`
```python
# Cháº¡y 1 coroutine
asyncio.run(say_hello())  # âœ… CHáº Y

# Cháº¡y nhiá»u coroutines song song
await asyncio.gather(task1, task2, task3)  # âœ… CHáº Y Táº¤T Cáº¢
```

</details>

---

### â“ CÃ¢u 7: Äoáº¡n code nÃ y lÃ m gÃ¬? Táº¡i sao CHÆ¯A cháº¡y ngay?

```python
tasks = [
    ask_llm_async(i+1, q) 
    for i, q in enumerate(questions)
]
```

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

Äoáº¡n code nÃ y **táº¡o danh sÃ¡ch 3 coroutine objects** (chÆ°a cháº¡y):

1. `ask_llm_async(1, "CÃ¢u há»i 1")` â†’ coroutine object
2. `ask_llm_async(2, "CÃ¢u há»i 2")` â†’ coroutine object
3. `ask_llm_async(3, "CÃ¢u há»i 3")` â†’ coroutine object

**ChÆ°a cháº¡y vÃ¬:** HÃ m `async` chá»‰ táº¡o ra "lá»i há»©a", cáº§n `await` hoáº·c `asyncio.gather()` Ä‘á»ƒ kÃ­ch hoáº¡t!

</details>

---

### â“ CÃ¢u 8: `asyncio.gather(*tasks)` hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

```python
results = await asyncio.gather(*tasks)
```

| Pháº§n | Ã nghÄ©a |
|------|---------|
| `*tasks` | Unpack list thÃ nh tá»«ng coroutine riÃªng láº» |
| `asyncio.gather()` | Cháº¡y táº¥t cáº£ coroutines **SONG SONG** |
| `await` | Äá»£i cho Ä‘áº¿n khi **Táº¤T Cáº¢** Ä‘á»u hoÃ n thÃ nh |
| `results` | List chá»©a káº¿t quáº£ cá»§a táº¥t cáº£ tasks (theo thá»© tá»±) |

</details>

---

## ğŸ”¤ Tokenization (NgÃ y 1)

### â“ CÃ¢u 9: Token lÃ  gÃ¬? LLM cÃ³ hiá»ƒu "tá»«" khÃ´ng?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**LLM KHÃ”NG hiá»ƒu tá»« nhÆ° con ngÆ°á»i!** ChÃºng xá»­ lÃ½ cÃ¡c **Token** - lÃ  cÃ¡c máº£nh vÄƒn báº£n nhá».

Token cÃ³ thá»ƒ lÃ :
- Má»™t tá»« hoÃ n chá»‰nh: `"Hello"` â†’ 1 token
- Má»™t pháº§n cá»§a tá»«: `"Láº­p trÃ¬nh"` â†’ `"L"` + `"áº­p"` + `" trÃ¬nh"` = 3 tokens
- Dáº¥u cÃ¢u hoáº·c khoáº£ng tráº¯ng: `","` â†’ 1 token

**LLM thá»±c cháº¥t lÃ  bá»™ mÃ¡y dá»± Ä‘oÃ¡n xÃ¡c suáº¥t token tiáº¿p theo!**

</details>

---

### â“ CÃ¢u 10: Táº¡i sao LLM thÆ°á»ng tÃ­nh toÃ¡n sai?

```python
"12345"    â†’ ['123', '45']      # 2 tokens
"1000000"  â†’ ['100', '000', '0'] # 3 tokens
```

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**VÃ¬ cÃ¡c con sá»‘ bá»‹ chia cáº¯t thÃ nh tokens khÃ´ng logic!**

| Sá»‘ | CÃ¡ch LLM nhÃ¬n | Váº¥n Ä‘á» |
|----|---------------|--------|
| `12345` | `123` + `45` | KhÃ´ng pháº£i tá»«ng chá»¯ sá»‘ |
| `1000000` | `100` + `000` + `0` | Chia khÃ´ng Ä‘á»u |

LLM xá»­ lÃ½ toÃ¡n trÃªn cÃ¡c token, khÃ´ng pháº£i trÃªn tá»«ng chá»¯ sá»‘ â†’ dá»… tÃ­nh sai!

</details>

---

### â“ CÃ¢u 11: Táº¡i sao LLM Ä‘áº¿m sai sá»‘ chá»¯ 'r' trong "strawberry"?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

```
"strawberry" Ä‘Æ°á»£c tokenize thÃ nh:
   Token 1: 'st'    (0 chá»¯ 'r')
   Token 2: 'raw'   (1 chá»¯ 'r')
   Token 3: 'berry' (2 chá»¯ 'r')
```

**LLM khÃ´ng nhÃ¬n tá»«ng chá»¯ cÃ¡i!** NÃ³ chá»‰ tháº¥y 3 tokens.

Äá»ƒ Ä‘áº¿m chá»¯ 'r', LLM pháº£i:
1. Hiá»ƒu má»—i token chá»©a nhá»¯ng chá»¯ gÃ¬ (khÃ³)
2. Äáº¿m trong tá»«ng token (khÃ´ng Ä‘Æ°á»£c train cho viá»‡c nÃ y)

â†’ ÄÃ¢y lÃ  lÃ½ do LLM Ä‘á»i cÅ© thÆ°á»ng tráº£ lá»i sai: "2 chá»¯ r" thay vÃ¬ "3 chá»¯ r"

</details>

---

### â“ CÃ¢u 12: LLM Ä‘á»i má»›i (GPT-4o, Claude 3.5) fix váº¥n Ä‘á» Ä‘áº¿m chá»¯ cÃ¡i báº±ng cÃ¡ch nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

CÃ¡c LLM Ä‘á»i má»›i sá»­ dá»¥ng **3 ká»¹ thuáº­t chÃ­nh**:

**1. Chain-of-Thought (Suy luáº­n tá»«ng bÆ°á»›c)**
```
BÆ°á»›c 1: Liá»‡t kÃª tá»«ng chá»¯: s-t-r-a-w-b-e-r-r-y
BÆ°á»›c 2: ÄÃ¡nh dáº¥u chá»¯ 'r': s-t-[r]-a-w-b-e-[r]-[r]-y
BÆ°á»›c 3: Äáº¿m: 3 chá»¯ 'r'
```

**2. Tool Use (Sá»­ dá»¥ng cÃ´ng cá»¥)**
- LLM gá»i code Python Ä‘á»ƒ Ä‘áº¿m chÃ­nh xÃ¡c:
```python
"strawberry".count('r')  # â†’ 3
```

**3. Training tá»‘t hÆ¡n**
- ÄÆ°á»£c train vá»›i nhiá»u bÃ i toÃ¡n character-level
- Há»c cÃ¡ch "phÃ¢n tÃ­ch" token thÃ nh tá»«ng chá»¯ cÃ¡i khi cáº§n

**Káº¿t quáº£:** GPT-4o, Claude 3.5, Gemini 1.5 Ä‘á»u tráº£ lá»i Ä‘Ãºng "3 chá»¯ r"!

</details>

---

### â“ CÃ¢u 13: Chi phÃ­ API Ä‘Æ°á»£c tÃ­nh nhÆ° tháº¿ nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Chi phÃ­ tÃ­nh theo TOKEN, khÃ´ng pháº£i tá»« hay kÃ½ tá»±!**

| Text | KÃ½ tá»± | Tá»« | Token | Chi phÃ­* |
|------|-------|-----|-------|----------|
| `Hello` | 5 | 1 | 1 | $0.000005 |
| `Xin chÃ o` | 8 | 2 | 3 | $0.000015 |
| `Láº­p trÃ¬nh AI` | 12 | 3 | 4 | $0.000020 |

*Giáº£ sá»­ $0.005/1K tokens

**LÆ°u Ã½:** Tiáº¿ng Viá»‡t thÆ°á»ng tá»‘n nhiá»u token hÆ¡n tiáº¿ng Anh!

</details>

---

## ğŸ“ Files trong project

| File | MÃ´ táº£ |
|------|-------|
| `hello_llm.py` | Demo gá»i Azure OpenAI cÆ¡ báº£n (sync) |
| `async_llm.py` | Demo gá»i Azure OpenAI báº¥t Ä‘á»“ng bá»™ (async) |
| `token_kung_fu.py` | Demo tokenization - cÃ¡ch LLM "nhÃ¬n" vÄƒn báº£n |

---

## ğŸ”§ Cáº¥u hÃ¬nh

Táº¡o file `.env` vá»›i cÃ¡c biáº¿n:
```
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_DEPLOYMENT=your_deployment_name
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```
