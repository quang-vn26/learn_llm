# ğŸ“ Learn AI - Lá»™ trÃ¬nh AI Engineer

> **Má»¥c tiÃªu tá»•ng quan:** Tá»« láº­p trÃ¬nh viÃªn â†’ AI Engineer qua lá»™ trÃ¬nh 12 tuáº§n thá»±c chiáº¿n.
> Repository nÃ y chá»©a code thá»±c hÃ nh vÃ  kiáº¿n thá»©c Ã´n táº­p theo tá»«ng tuáº§n.

---

## ğŸ“… TUáº¦N 1: Python Async & "CÃº báº¯t tay" vá»›i API (The Handshake)

> **Má»¥c tiÃªu:** Hiá»ƒu táº¡i sao AI Engineer cáº§n AsyncIO vÃ  gá»­i Ä‘Æ°á»£c request Ä‘áº§u tiÃªn lÃªn OpenAI/Anthropic.
>
> **LÃ½ do cá»‘t lÃµi:** CÃ¡c LLM API ráº¥t cháº­m (cÃ³ khi máº¥t 3-10 giÃ¢y Ä‘á»ƒ pháº£n há»“i). Náº¿u dÃ¹ng code Ä‘á»“ng bá»™ (nhÆ° cÃ¡ch viáº¿t Java cÆ¡ báº£n), server cá»§a báº¡n sáº½ bá»‹ treo khi chá» Ä‘á»£i. Báº¡n cáº§n `asyncio` Ä‘á»ƒ xá»­ lÃ½ hÃ ng ngÃ n request cÃ¹ng lÃºc.

### ğŸ“Œ Thá»© 2 - Thá»© 3: Python Async/Await Deep Dive

**LÃ½ thuyáº¿t:** TÃ¬m hiá»ƒu Event Loop trong Python (khÃ¡c vá»›i Thread trong Java). PhÃ¢n biá»‡t `def` thÆ°á»ng vÃ  `async def`.

**Thá»±c hÃ nh:** Viáº¿t script dÃ¹ng `asyncio` vÃ  `aiohttp` Ä‘á»ƒ gá»­i 50 request giáº£ láº­p cÃ¹ng lÃºc vÃ  in ra thá»i gian hoÃ n thÃ nh so vá»›i cháº¡y tuáº§n tá»±.

**TÆ° duy nguyÃªn báº£n:** Äá»«ng chá»‰ copy code. HÃ£y tá»± há»i: *"Khi lá»‡nh `await` cháº¡y, CPU Ä‘ang lÃ m gÃ¬?"*

#### â“ CÃ¢u 1: Sá»± khÃ¡c biá»‡t giá»¯a Sync vÃ  Async lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Äá»“ng bá»™ (Sync)** - Cháº¡y tuáº§n tá»±, pháº£i Ä‘á»£i task trÆ°á»›c xong má»›i cháº¡y task sau:
```
Request 1 â”€â”€â”€â”€> (3s) â”€â”€â”€â”€> Xong
                           Request 2 â”€â”€â”€â”€> (4s) â”€â”€â”€â”€> Xong
                                                      Request 3 â”€â”€â”€â”€> (5s) â”€â”€â”€â”€> Xong
Tá»•ng: 12 giÃ¢y
```

**Báº¥t Ä‘á»“ng bá»™ (Async)** - Cháº¡y song song, táº¥t cáº£ task cháº¡y cÃ¹ng lÃºc:
```
Request 1 â”€â”€â”€â”€> (3s) â”€â”€â”€â”€> Xong
Request 2 â”€â”€â”€â”€> (4s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Xong
Request 3 â”€â”€â”€â”€> (5s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Xong
Tá»•ng: ~5 giÃ¢y (báº±ng task lÃ¢u nháº¥t)
```

</details>

---

#### â“ CÃ¢u 2: Táº¡i sao gá»i hÃ m `async` mÃ  nÃ³ khÃ´ng cháº¡y ngay?

```python
async def say_hello():
    print("Hello!")

result = say_hello()  # Táº¡i sao khÃ´ng in ra "Hello!"?
```

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

Khi Ä‘á»‹nh nghÄ©a hÃ m vá»›i `async def`, Python biáº¿n nÃ³ thÃ nh **coroutine function**.

| Loáº¡i hÃ m | Khi gá»i | Káº¿t quáº£ |
|----------|---------|---------|
| HÃ m thÆ°á»ng `def` | `say_hello()` | **Thá»±c thi ngay** |
| HÃ m async `async def` | `say_hello()` | **KhÃ´ng thá»±c thi**, tráº£ vá» `coroutine object` |

**Coroutine** giá»‘ng nhÆ° **"cÃ´ng thá»©c náº¥u Äƒn"** - báº¡n cÃ³ cÃ´ng thá»©c nhÆ°ng chÆ°a náº¥u!

</details>

---

#### â“ CÃ¢u 3: LÃ m sao Ä‘á»ƒ coroutine THá»°C Sá»° cháº¡y?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**CÃ¡ch 1:** DÃ¹ng `await` (bÃªn trong hÃ m async khÃ¡c)
```python
async def main():
    result = await say_hello()  # âœ… CHáº Y vÃ  Ä‘á»£i káº¿t quáº£
```

**CÃ¡ch 2:** DÃ¹ng `asyncio.run()` hoáº·c `asyncio.gather()`
```python
# Cháº¡y 1 coroutine
asyncio.run(say_hello())  # âœ… CHáº Y

# Cháº¡y nhiá»u coroutines song song
await asyncio.gather(task1, task2, task3)  # âœ… CHáº Y Táº¤T Cáº¢
```

</details>

---

#### â“ CÃ¢u 4: Äoáº¡n code nÃ y lÃ m gÃ¬? Táº¡i sao CHÆ¯A cháº¡y ngay?

```python
tasks = [
    ask_llm_async(i+1, q) 
    for i, q in enumerate(questions)
]
```

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

Äoáº¡n code nÃ y **táº¡o danh sÃ¡ch 3 coroutine objects** (chÆ°a cháº¡y):

1. `ask_llm_async(1, "CÃ¢u há»i 1")` â†’ coroutine object
2. `ask_llm_async(2, "CÃ¢u há»i 2")` â†’ coroutine object
3. `ask_llm_async(3, "CÃ¢u há»i 3")` â†’ coroutine object

**ChÆ°a cháº¡y vÃ¬:** HÃ m `async` chá»‰ táº¡o ra "lá»i há»©a", cáº§n `await` hoáº·c `asyncio.gather()` Ä‘á»ƒ kÃ­ch hoáº¡t!

</details>

---

#### â“ CÃ¢u 5: `asyncio.gather(*tasks)` hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

```python
results = await asyncio.gather(*tasks)
```

| Pháº§n | Ã nghÄ©a |
|------|---------|
| `*tasks` | Unpack list thÃ nh tá»«ng coroutine riÃªng láº» |
| `asyncio.gather()` | Cháº¡y táº¥t cáº£ coroutines **SONG SONG** |
| `await` | Äá»£i cho Ä‘áº¿n khi **Táº¤T Cáº¢** Ä‘á»u hoÃ n thÃ nh |
| `results` | List chá»©a káº¿t quáº£ cá»§a táº¥t cáº£ tasks (theo thá»© tá»±) |

</details>

---

### ğŸ“Œ Thá»© 4 - Thá»© 5: LÃ m chá»§ JSON & API Request

**CÃ´ng cá»¥:** ÄÄƒng kÃ½ API Key (OpenAI hoáº·c DeepSeek/Anthropic). CÃ i thÆ° viá»‡n `openai` hoáº·c dÃ¹ng `requests` thuáº§n.

**Thá»±c hÃ nh:** Gá»­i má»™t prompt Ä‘Æ¡n giáº£n ("Hello AI") vÃ  nháº­n vá» response JSON.

**PhÃ¢n tÃ­ch:** Äá»«ng chá»‰ láº¥y ná»™i dung tráº£ lá»i. HÃ£y `print` toÃ n bá»™ JSON tráº£ vá» Ä‘á»ƒ xem cÃ¡c trÆ°á»ng: `usage` (sá»‘ token Ä‘Ã£ dÃ¹ng), `finish_reason` (táº¡i sao nÃ³ dá»«ng?), `model` (phiÃªn báº£n nÃ o). ÄÃ¢y lÃ  bÆ°á»›c **"PhÃ¡ vá»¡ há»™p Ä‘en"**.

#### â“ CÃ¢u 6: LLM viáº¿t táº¯t cá»§a tá»« gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**LLM = Large Language Model** (MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n)

| ThÃ nh pháº§n | Ã nghÄ©a |
|------------|---------|
| **Large** | Lá»›n - hÃ ng tá»· tham sá»‘ (parameters), Ä‘Æ°á»£c train trÃªn lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“ |
| **Language** | NgÃ´n ngá»¯ - hiá»ƒu vÃ  sinh ra vÄƒn báº£n cá»§a con ngÆ°á»i |
| **Model** | MÃ´ hÃ¬nh - thuáº­t toÃ¡n AI Ä‘Æ°á»£c huáº¥n luyá»‡n |

**VÃ­ dá»¥ cÃ¡c LLM phá»• biáº¿n:**
- GPT-4, GPT-4o (OpenAI)
- Claude 3.5 Sonnet (Anthropic)
- Gemini 1.5, Gemini 2.0 (Google)
- Llama 3 (Meta)

**LLM lÃ m Ä‘Æ°á»£c gÃ¬?**
- Tráº£ lá»i cÃ¢u há»i, viáº¿t vÄƒn báº£n
- Dá»‹ch thuáº­t, tÃ³m táº¯t
- Viáº¿t code, sá»­a lá»—i
- PhÃ¢n tÃ­ch dá»¯ liá»‡u

</details>

---

#### â“ CÃ¢u 7: CÆ¡ cháº¿ chÃ­nh cá»§a Transformer lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Self-Attention** (CÆ¡ cháº¿ Tá»± ChÃº Ã) lÃ  trÃ¡i tim cá»§a kiáº¿n trÃºc Transformer!

**Self-Attention lÃ  gÃ¬?**

NÃ³ cho phÃ©p má»—i tá»« trong cÃ¢u "nhÃ¬n" vÃ  "chÃº Ã½" Ä‘áº¿n táº¥t cáº£ cÃ¡c tá»« khÃ¡c Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh.

**VÃ­ dá»¥ minh há»a:**

```
CÃ¢u: "Con mÃ¨o Ä‘uá»•i con chuá»™t vÃ¬ nÃ³ Ä‘Ã³i"
                                  â†“
                          "nÃ³" chá»‰ ai?
```

Self-Attention giÃºp model hiá»ƒu Ä‘Æ°á»£c "nÃ³" chá»‰ **"con mÃ¨o"** (vÃ¬ mÃ¨o má»›i Ä‘Ã³i vÃ  Ä‘uá»•i chuá»™t).

**CÃ¡ch hoáº¡t Ä‘á»™ng Ä‘Æ¡n giáº£n:**

```
BÆ°á»›c 1: Má»—i tá»« táº¡o ra 3 vector: Query (Q), Key (K), Value (V)
BÆ°á»›c 2: TÃ­nh Ä‘á»™ "liÃªn quan" giá»¯a cÃ¡c tá»«: Q Ã— K
BÆ°á»›c 3: DÃ¹ng Ä‘á»™ liÃªn quan lÃ m trá»ng sá»‘ Ä‘á»ƒ káº¿t há»£p cÃ¡c Value
```

| Tá»« | ChÃº Ã½ nhiá»u Ä‘áº¿n | LÃ½ do |
|----|-----------------|-------|
| "nÃ³" | "mÃ¨o" (80%), "chuá»™t" (15%) | Ngá»¯ cáº£nh "Ä‘uá»•i" vÃ  "Ä‘Ã³i" |
| "Ä‘uá»•i" | "mÃ¨o" (70%), "chuá»™t" (25%) | MÃ¨o lÃ  chá»§ thá»ƒ hÃ nh Ä‘á»™ng |

**Táº¡i sao Self-Attention máº¡nh?**
- Hiá»ƒu Ä‘Æ°á»£c ngá»¯ cáº£nh xa (khÃ´ng giá»›i háº¡n khoáº£ng cÃ¡ch tá»«)
- Xá»­ lÃ½ song song (nhanh hÆ¡n RNN/LSTM)
- Linh hoáº¡t vá»›i nhiá»u loáº¡i quan há»‡

</details>

---

#### â“ CÃ¢u 8: Tokenization lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Tokenization** lÃ  quÃ¡ trÃ¬nh **chia vÄƒn báº£n thÃ nh cÃ¡c máº£nh nhá» (tokens)** Ä‘á»ƒ LLM cÃ³ thá»ƒ xá»­ lÃ½.

**Táº¡i sao cáº§n Tokenization?**

LLM khÃ´ng thá»ƒ Ä‘á»c text trá»±c tiáº¿p! NÃ³ cáº§n chuyá»ƒn text â†’ sá»‘ (token IDs).

```
"Hello World" â†’ [15496, 2159] â†’ LLM xá»­ lÃ½ â†’ [Output IDs] â†’ "Xin chÃ o"
```

**VÃ­ dá»¥ Tokenization thá»±c táº¿:**

| VÄƒn báº£n | Tokens | Sá»‘ lÆ°á»£ng |
|---------|--------|----------|
| `"Hello"` | `["Hello"]` | 1 token |
| `"Hello World"` | `["Hello", " World"]` | 2 tokens |
| `"Xin chÃ o"` | `["X", "in", " ch", "Ã o"]` | 4 tokens |
| `"GPT-4"` | `["G", "PT", "-", "4"]` | 4 tokens |
| `"strawberry"` | `["st", "raw", "berry"]` | 3 tokens |

**Quy luáº­t tokenization:**
```python
# Tá»« phá»• biáº¿n â†’ Ã­t tokens
"the"        â†’ ["the"]           # 1 token
"computer"   â†’ ["computer"]       # 1 token

# Tá»« hiáº¿m hoáº·c tiáº¿ng Viá»‡t â†’ nhiá»u tokens hÆ¡n
"Viá»‡t Nam"   â†’ ["Vi", "á»‡t", " Nam"]  # 3 tokens
"Láº­p trÃ¬nh"  â†’ ["L", "áº­p", " tr", "Ã¬nh"]  # 4 tokens
```

**Code demo:**
```python
import tiktoken

encoder = tiktoken.encoding_for_model("gpt-4")

text = "Xin chÃ o Viá»‡t Nam!"
tokens = encoder.encode(text)

print(f"Text: {text}")
print(f"Token IDs: {tokens}")
print(f"Sá»‘ tokens: {len(tokens)}")

# Xem tá»«ng token lÃ  gÃ¬
for token_id in tokens:
    print(f"  {token_id} â†’ '{encoder.decode([token_id])}'")
```

**Output:**
```
Text: Xin chÃ o Viá»‡t Nam!
Token IDs: [55, 258, 559, 3975, 79136, 23561, 0]
Sá»‘ tokens: 7
  55 â†’ 'X'
  258 â†’ 'in'
  559 â†’ ' ch'
  3975 â†’ 'Ã o'
  79136 â†’ ' Vi'
  23561 â†’ 'á»‡t'
  ...
```

**ğŸ’¡ Ghi nhá»›:** Tiáº¿ng Viá»‡t tá»‘n nhiá»u tokens hÆ¡n tiáº¿ng Anh â†’ chi phÃ­ API cao hÆ¡n!

</details>

---

### ğŸ“Œ Thá»© 6 - Thá»© 7: Xá»­ lÃ½ lá»—i & Retry

**Váº¥n Ä‘á»:** API AI thÆ°á»ng xuyÃªn bá»‹ lá»—i `429` (Too Many Requests) hoáº·c `500` (Internal Server Error).

**Thá»±c hÃ nh:** Viáº¿t hÃ m wrapper (bá»c) viá»‡c gá»i API vá»›i cÆ¡ cháº¿ **exponential backoff** (thá»­ láº¡i sau thá»i gian tÄƒng dáº§n) báº±ng thÆ° viá»‡n `tenacity` hoáº·c tá»± viáº¿t logic loop.

#### â“ CÃ¢u 9: Exponential Backoff lÃ  gÃ¬? Táº¡i sao cáº§n cho API LLM?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Exponential Backoff** = Chiáº¿n lÆ°á»£c thá»­ láº¡i (retry) vá»›i **thá»i gian chá» tÄƒng gáº¥p Ä‘Ã´i** sau má»—i láº§n tháº¥t báº¡i.

```
Láº§n 1 tháº¥t báº¡i â†’ Chá» 1s  â†’ Thá»­ láº¡i
Láº§n 2 tháº¥t báº¡i â†’ Chá» 2s  â†’ Thá»­ láº¡i
Láº§n 3 tháº¥t báº¡i â†’ Chá» 4s  â†’ Thá»­ láº¡i
Láº§n 4 tháº¥t báº¡i â†’ Chá» 8s  â†’ Thá»­ láº¡i
Láº§n 5 tháº¥t báº¡i â†’ Chá» 16s â†’ Thá»­ láº¡i
```

**Táº¡i sao cáº§n?**

| Lá»—i | NguyÃªn nhÃ¢n | Giáº£i phÃ¡p |
|-----|-------------|-----------|
| `429 Too Many Requests` | Gá»­i quÃ¡ nhiá»u request/phÃºt | Chá» rá»“i thá»­ láº¡i |
| `500 Internal Server Error` | Server bá»‹ quÃ¡ táº£i | Chá» rá»“i thá»­ láº¡i |
| `503 Service Unavailable` | Server Ä‘ang báº£o trÃ¬ | Chá» rá»“i thá»­ láº¡i |
| `Timeout` | Máº¡ng cháº­m hoáº·c response quÃ¡ lá»›n | Chá» rá»“i thá»­ láº¡i |

**Táº¡i sao khÃ´ng retry ngay láº­p tá»©c?**
- Náº¿u retry ngay â†’ server váº«n chÆ°a phá»¥c há»“i â†’ láº¡i lá»—i â†’ vÃ²ng láº·p vÃ´ táº­n!
- Exponential backoff cho server **thá»i gian há»“i phá»¥c**, Ä‘á»“ng thá»i trÃ¡nh "Ä‘á»• Ä‘Ã¨o" (thundering herd).

**Code demo vá»›i `tenacity`:**
```python
from tenacity import retry, wait_exponential, stop_after_attempt

@retry(
    wait=wait_exponential(multiplier=1, min=1, max=30),  # 1s, 2s, 4s, 8s... max 30s
    stop=stop_after_attempt(5)  # Tá»‘i Ä‘a 5 láº§n thá»­
)
async def call_llm_with_retry(prompt):
    response = await client.chat.completions.create(
        model=deployment,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

**Code demo tá»± viáº¿t (khÃ´ng dÃ¹ng thÆ° viá»‡n):**
```python
import asyncio
import random

async def call_llm_with_retry(prompt, max_retries=5):
    for attempt in range(max_retries):
        try:
            response = await client.chat.completions.create(
                model=deployment,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
        except Exception as e:
            if attempt == max_retries - 1:
                raise  # Háº¿t láº§n thá»­ â†’ raise lá»—i
            
            wait_time = (2 ** attempt) + random.uniform(0, 1)  # Jitter
            print(f"âš ï¸ Lá»—i: {e}. Thá»­ láº¡i sau {wait_time:.1f}s...")
            await asyncio.sleep(wait_time)
```

**ğŸ’¡ Máº¹o:** ThÃªm **jitter** (random nhá») vÃ o thá»i gian chá» Ä‘á»ƒ trÃ¡nh nhiá»u client retry cÃ¹ng lÃºc.

</details>

---

## ğŸ“… TUáº¦N 2: Giáº£i mÃ£ "Token" & Prompt Engineering

> **Má»¥c tiÃªu:** Hiá»ƒu ngÃ´n ngá»¯ cá»§a mÃ¡y. MÃ¡y khÃ´ng hiá»ƒu chá»¯ "YÃªu", nÃ³ chá»‰ hiá»ƒu token `12345`.
>
> **LÃ½ do cá»‘t lÃµi:** LLM tÃ­nh tiá»n vÃ  giá»›i háº¡n bá»™ nhá»› dá»±a trÃªn **token**, khÃ´ng pháº£i tá»« (word). KhÃ´ng hiá»ƒu token sáº½ dáº«n Ä‘áº¿n máº¥t tiá»n oan vÃ  lá»—i cáº¯t chuá»—i.

### ğŸ“Œ Thá»© 2 - Thá»© 3: Tokenization & Tiktoken

**LÃ½ thuyáº¿t:** CÃ i thÆ° viá»‡n `tiktoken`.

**Thá»±c hÃ nh:**
- Nháº­p cÃ¢u: "Xin chÃ o, tÃ´i lÃ  ká»¹ sÆ° AI"
- DÃ¹ng `tiktoken` Ä‘á»ƒ xem nÃ³ bá»‹ tÃ¡ch thÃ nh bao nhiÃªu token? (Tiáº¿ng Viá»‡t thÆ°á»ng tá»‘n token hÆ¡n tiáº¿ng Anh)
- So sÃ¡nh sá»± khÃ¡c biá»‡t giá»¯a `len(string)` vÃ  sá»‘ lÆ°á»£ng token

#### â“ CÃ¢u 10: Token lÃ  gÃ¬? LLM cÃ³ hiá»ƒu "tá»«" khÃ´ng?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**LLM KHÃ”NG hiá»ƒu tá»« nhÆ° con ngÆ°á»i!** ChÃºng xá»­ lÃ½ cÃ¡c **Token** - lÃ  cÃ¡c máº£nh vÄƒn báº£n nhá».

Token cÃ³ thá»ƒ lÃ :
- Má»™t tá»« hoÃ n chá»‰nh: `"Hello"` â†’ 1 token
- Má»™t pháº§n cá»§a tá»«: `"Láº­p trÃ¬nh"` â†’ `"L"` + `"áº­p"` + `" trÃ¬nh"` = 3 tokens
- Dáº¥u cÃ¢u hoáº·c khoáº£ng tráº¯ng: `","` â†’ 1 token

**LLM thá»±c cháº¥t lÃ  bá»™ mÃ¡y dá»± Ä‘oÃ¡n xÃ¡c suáº¥t token tiáº¿p theo!**

</details>

---

#### â“ CÃ¢u 11: Táº¡i sao LLM thÆ°á»ng tÃ­nh toÃ¡n sai?

```python
"12345"    â†’ ['123', '45']      # 2 tokens
"1000000"  â†’ ['100', '000', '0'] # 3 tokens
```

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**VÃ¬ cÃ¡c con sá»‘ bá»‹ chia cáº¯t thÃ nh tokens khÃ´ng logic!**

| Sá»‘ | CÃ¡ch LLM nhÃ¬n | Váº¥n Ä‘á» |
|----|---------------|--------|
| `12345` | `123` + `45` | KhÃ´ng pháº£i tá»«ng chá»¯ sá»‘ |
| `1000000` | `100` + `000` + `0` | Chia khÃ´ng Ä‘á»u |

LLM xá»­ lÃ½ toÃ¡n trÃªn cÃ¡c token, khÃ´ng pháº£i trÃªn tá»«ng chá»¯ sá»‘ â†’ dá»… tÃ­nh sai!

</details>

---

#### â“ CÃ¢u 12: Táº¡i sao LLM Ä‘áº¿m sai sá»‘ chá»¯ 'r' trong "strawberry"?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

```
"strawberry" Ä‘Æ°á»£c tokenize thÃ nh:
   Token 1: 'st'    (0 chá»¯ 'r')
   Token 2: 'raw'   (1 chá»¯ 'r')
   Token 3: 'berry' (2 chá»¯ 'r')
```

**LLM khÃ´ng nhÃ¬n tá»«ng chá»¯ cÃ¡i!** NÃ³ chá»‰ tháº¥y 3 tokens.

Äá»ƒ Ä‘áº¿m chá»¯ 'r', LLM pháº£i:
1. Hiá»ƒu má»—i token chá»©a nhá»¯ng chá»¯ gÃ¬ (khÃ³)
2. Äáº¿m trong tá»«ng token (khÃ´ng Ä‘Æ°á»£c train cho viá»‡c nÃ y)

â†’ ÄÃ¢y lÃ  lÃ½ do LLM Ä‘á»i cÅ© thÆ°á»ng tráº£ lá»i sai: "2 chá»¯ r" thay vÃ¬ "3 chá»¯ r"

</details>

---

#### â“ CÃ¢u 13: LLM Ä‘á»i má»›i (GPT-4o, Claude 3.5) fix váº¥n Ä‘á» Ä‘áº¿m chá»¯ cÃ¡i báº±ng cÃ¡ch nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

CÃ¡c LLM Ä‘á»i má»›i sá»­ dá»¥ng **3 ká»¹ thuáº­t chÃ­nh**:

**1. Chain-of-Thought (Suy luáº­n tá»«ng bÆ°á»›c)**
```
BÆ°á»›c 1: Liá»‡t kÃª tá»«ng chá»¯: s-t-r-a-w-b-e-r-r-y
BÆ°á»›c 2: ÄÃ¡nh dáº¥u chá»¯ 'r': s-t-[r]-a-w-b-e-[r]-[r]-y
BÆ°á»›c 3: Äáº¿m: 3 chá»¯ 'r'
```

**2. Tool Use (Sá»­ dá»¥ng cÃ´ng cá»¥)**
- LLM gá»i code Python Ä‘á»ƒ Ä‘áº¿m chÃ­nh xÃ¡c:
```python
"strawberry".count('r')  # â†’ 3
```

**3. Training tá»‘t hÆ¡n**
- ÄÆ°á»£c train vá»›i nhiá»u bÃ i toÃ¡n character-level
- Há»c cÃ¡ch "phÃ¢n tÃ­ch" token thÃ nh tá»«ng chá»¯ cÃ¡i khi cáº§n

**Káº¿t quáº£:** GPT-4o, Claude 3.5, Gemini 1.5 Ä‘á»u tráº£ lá»i Ä‘Ãºng "3 chá»¯ r"!

</details>

---

#### â“ CÃ¢u 14: Chi phÃ­ API Ä‘Æ°á»£c tÃ­nh nhÆ° tháº¿ nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Chi phÃ­ tÃ­nh theo TOKEN, khÃ´ng pháº£i tá»« hay kÃ½ tá»±!**

| Text | KÃ½ tá»± | Tá»« | Token | Chi phÃ­* |
|------|-------|-----|-------|----------|
| `Hello` | 5 | 1 | 1 | $0.000005 |
| `Xin chÃ o` | 8 | 2 | 3 | $0.000015 |
| `Láº­p trÃ¬nh AI` | 12 | 3 | 4 | $0.000020 |

*Giáº£ sá»­ $0.005/1K tokens

**LÆ°u Ã½:** Tiáº¿ng Viá»‡t thÆ°á»ng tá»‘n nhiá»u token hÆ¡n tiáº¿ng Anh!

</details>

---

### ğŸ“Œ Thá»© 4: BÃ i táº­p "Token Kung Fu" (Code Kata)

**Äá» bÃ i:** Viáº¿t má»™t hÃ m `truncate_text(text, max_tokens)` nháº­n vÃ o má»™t Ä‘oáº¡n vÄƒn dÃ i vÃ  sá»‘ token tá»‘i Ä‘a.

**YÃªu cáº§u:** Cáº¯t Ä‘oáº¡n vÄƒn sao cho khÃ´ng vÆ°á»£t quÃ¡ sá»‘ token quy Ä‘á»‹nh, nhÆ°ng khÃ´ng Ä‘Æ°á»£c cáº¯t giá»¯a chá»«ng má»™t tá»« hoáº·c má»™t cÃ¢u (náº¿u cÃ³ thá»ƒ).

**Má»¥c Ä‘Ã­ch:** Ká»¹ nÄƒng nÃ y cá»±c ká»³ quan trá»ng khi náº¡p dá»¯ liá»‡u vÃ o Context Window sau nÃ y.

#### â“ CÃ¢u 15: LÃ m tháº¿ nÃ o Ä‘á»ƒ cáº¯t vÄƒn báº£n Ä‘Ãºng theo token mÃ  khÃ´ng cáº¯t giá»¯a tá»«?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Váº¥n Ä‘á»:** `text[:100]` cáº¯t theo kÃ½ tá»± â†’ cÃ³ thá»ƒ cáº¯t giá»¯a tá»« hoáº·c giá»¯a multi-byte character (tiáº¿ng Viá»‡t!). Ta cáº§n cáº¯t theo **token** vÃ  giá»¯ cho output tá»± nhiÃªn.

**Thuáº­t toÃ¡n:**
```
1. Encode toÃ n bá»™ text â†’ list token IDs
2. Láº¥y max_tokens IDs Ä‘áº§u tiÃªn
3. Decode láº¡i thÃ nh text
4. Kiá»ƒm tra: cÃ³ bá»‹ cáº¯t giá»¯a tá»«/cÃ¢u khÃ´ng?
5. Náº¿u cÃ³ â†’ lÃ¹i láº¡i Ä‘áº¿n ranh giá»›i tá»«/cÃ¢u gáº§n nháº¥t
```

**Code demo:**
```python
import tiktoken

def truncate_text(text: str, max_tokens: int) -> str:
    """
    Cáº¯t text sao cho khÃ´ng vÆ°á»£t quÃ¡ max_tokens,
    khÃ´ng cáº¯t giá»¯a tá»« hoáº·c cÃ¢u.
    """
    encoding = tiktoken.encoding_for_model("gpt-4o")
    tokens = encoding.encode(text)
    
    if len(tokens) <= max_tokens:
        return text  # KhÃ´ng cáº§n cáº¯t
    
    # Cáº¯t theo token
    truncated_tokens = tokens[:max_tokens]
    truncated_text = encoding.decode(truncated_tokens)
    
    # TÃ¬m ranh giá»›i cÃ¢u gáº§n nháº¥t (dáº¥u cháº¥m, cháº¥m há»i, cháº¥m than)
    sentence_ends = ['.', '!', '?', 'ã€‚']
    last_sentence_end = -1
    for i, char in enumerate(truncated_text):
        if char in sentence_ends:
            last_sentence_end = i
    
    if last_sentence_end > len(truncated_text) * 0.5:
        # Cáº¯t táº¡i ranh giá»›i cÃ¢u (náº¿u khÃ´ng máº¥t quÃ¡ nhiá»u ná»™i dung)
        return truncated_text[:last_sentence_end + 1]
    
    # Fallback: cáº¯t táº¡i ranh giá»›i tá»« (khoáº£ng tráº¯ng)
    last_space = truncated_text.rfind(' ')
    if last_space > 0:
        return truncated_text[:last_space] + "..."
    
    return truncated_text + "..."
```

**VÃ­ dá»¥ sá»­ dá»¥ng:**
```python
long_text = "TrÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘ang thay Ä‘á»•i tháº¿ giá»›i. " * 100
result = truncate_text(long_text, max_tokens=20)
print(f"Káº¿t quáº£ ({len(encoding.encode(result))} tokens): {result}")
```

**ğŸ’¡ Táº¡i sao ká»¹ nÄƒng nÃ y quan trá»ng?**
- **Context Window cÃ³ giá»›i háº¡n** (vÃ­ dá»¥: 128K tokens cho GPT-4o)
- Khi lÃ m RAG (Retrieval-Augmented Generation), báº¡n pháº£i nhÃ©t nhiá»u tÃ i liá»‡u vÃ o prompt â†’ cáº§n cáº¯t gá»n
- Cáº¯t sai â†’ máº¥t Ã½ nghÄ©a â†’ LLM tráº£ lá»i sai!

</details>

---

### ğŸ“Œ Thá»© 5 - Thá»© 6: Prompt Engineering as Code

**LÃ½ thuyáº¿t:** Prompt khÃ´ng pháº£i lÃ  vÄƒn xuÃ´i, nÃ³ lÃ  **logic**.

**Thá»±c hÃ nh:** Viáº¿t script Python sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t:
- **Zero-shot:** Há»i trá»±c tiáº¿p
- **Few-shot:** Cung cáº¥p 3 vÃ­ dá»¥ máº«u trong prompt (Input â†’ Output) trÆ°á»›c khi há»i cÃ¢u má»›i
- **Chain-of-Thought (CoT):** ThÃªm cÃ¢u "Let's think step by step" vÃ o prompt

#### â“ CÃ¢u 16: Zero-shot Prompting lÃ  gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Zero-shot** = Há»i LLM trá»±c tiáº¿p **KHÃ”NG** cung cáº¥p báº¥t ká»³ vÃ­ dá»¥ nÃ o.

LLM pháº£i tá»± hiá»ƒu task dá»±a vÃ o kiáº¿n thá»©c Ä‘Ã£ há»c sáºµn.

**VÃ­ dá»¥:**
```
Prompt: "PhÃ¢n loáº¡i cáº£m xÃºc cÃ¢u sau: 'Bá»™ phim nÃ y hay quÃ¡!'"
â†’ LLM tá»± hiá»ƒu cáº§n tráº£ lá»i: Positive
```

| Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|----------|------------|
| ÄÆ¡n giáº£n, nhanh | CÃ³ thá»ƒ sai format |
| Tá»‘n Ã­t token â†’ ráº» | KÃ©m chÃ­nh xÃ¡c vá»›i task Ä‘áº·c thÃ¹ |

**Khi nÃ o dÃ¹ng?** Task phá»• biáº¿n mÃ  LLM Ä‘Ã£ "biáº¿t" sáºµn (dá»‹ch thuáº­t, tÃ³m táº¯t, phÃ¢n loáº¡i Ä‘Æ¡n giáº£n).

</details>

---

#### â“ CÃ¢u 17: Few-shot Prompting lÃ  gÃ¬? Táº¡i sao cáº§n 3 vÃ­ dá»¥?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Few-shot** = Cung cáº¥p **vÃ­ dá»¥ máº«u (Input â†’ Output)** trong prompt trÆ°á»›c khi há»i cÃ¢u tháº­t.

```python
# Cáº¥u trÃºc Few-shot trong code:
messages = [
    {"role": "system", "content": "Báº¡n lÃ  trá»£ lÃ½ phÃ¢n loáº¡i cáº£m xÃºc."},

    # â”€â”€ VÃ­ dá»¥ 1 â”€â”€
    {"role": "user",      "content": '"MÃ³n Äƒn ngon tuyá»‡t!" â†’ PhÃ¢n loáº¡i?'},
    {"role": "assistant", "content": "Positive"},

    # â”€â”€ VÃ­ dá»¥ 2 â”€â”€
    {"role": "user",      "content": '"Dá»‹ch vá»¥ tá»‡ quÃ¡!" â†’ PhÃ¢n loáº¡i?'},
    {"role": "assistant", "content": "Negative"},

    # â”€â”€ VÃ­ dá»¥ 3 â”€â”€
    {"role": "user",      "content": '"Cá»­a hÃ ng má»Ÿ cá»­a 8h-22h." â†’ PhÃ¢n loáº¡i?'},
    {"role": "assistant", "content": "Neutral"},

    # â”€â”€ CÃ¢u há»i THáº¬T â”€â”€
    {"role": "user",      "content": '"Phim hay quÃ¡ xem 3 láº§n!" â†’ PhÃ¢n loáº¡i?'},
]
```

**Táº¡i sao 3 vÃ­ dá»¥?**
- 1 vÃ­ dá»¥: LLM cÃ³ thá»ƒ hiá»ƒu sai pattern
- 2 vÃ­ dá»¥: chÆ°a Ä‘á»§ Ä‘a dáº¡ng
- **3 vÃ­ dá»¥: Ä‘á»§ Ä‘á»ƒ LLM náº¯m rÃµ format + logic** â† Sweet spot
- 5+ vÃ­ dá»¥: tá»‘n token, Ã­t cáº£i thiá»‡n thÃªm

</details>

---

#### â“ CÃ¢u 18: Chain-of-Thought (CoT) lÃ  gÃ¬? "CÃ¢u tháº§n chÃº" nÃ o kÃ­ch hoáº¡t nÃ³?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**Chain-of-Thought (CoT)** = Buá»™c LLM **trÃ¬nh bÃ y logic Tá»ªNG BÆ¯á»šC** trÆ°á»›c khi Ä‘Æ°a ra Ä‘Ã¡p Ã¡n.

**"CÃ¢u tháº§n chÃº":** ThÃªm `"Let's think step by step"` (HÃ£y suy nghÄ© tá»«ng bÆ°á»›c) vÃ o cuá»‘i prompt!

**VÃ­ dá»¥ - BÃ i toÃ¡n KHÃ”NG cÃ³ CoT:**
```
Prompt: "Mua 5 Ã¡o, giÃ¡ 200k/chiáº¿c, giáº£m 15%, thuáº¿ 10%. Tá»•ng?"
â†’ LLM: "935,000 VNÄ"  (cÃ³ thá»ƒ Ä‘Ãºng hoáº·c sai, khÃ´ng rÃµ cÃ¡ch tÃ­nh)
```

**CÃ¹ng bÃ i toÃ¡n CÃ“ CoT:**
```
Prompt: "... Let's think step by step."
â†’ LLM:
  BÆ°á»›c 1: GiÃ¡ gá»‘c = 5 Ã— 200,000 = 1,000,000 VNÄ
  BÆ°á»›c 2: Giáº£m 15% = 1,000,000 Ã— 0.85 = 850,000 VNÄ
  BÆ°á»›c 3: Thuáº¿ 10% = 850,000 Ã— 1.10 = 935,000 VNÄ
  â†’ ÄÃ¡p Ã¡n: 935,000 VNÄ âœ…
```

| KhÃ´ng CoT | CÃ³ CoT |
|-----------|--------|
| ÄÃ¡p Ã¡n ngáº¯n, cÃ³ thá»ƒ sai | TrÃ¬nh bÃ y rÃµ rÃ ng tá»«ng bÆ°á»›c |
| Ãt token | Nhiá»u token hÆ¡n |
| KhÃ³ kiá»ƒm tra logic | Dá»… kiá»ƒm tra vÃ  debug |

</details>

---

#### â“ CÃ¢u 19: So sÃ¡nh chi phÃ­ token cá»§a 3 ká»¹ thuáº­t prompting?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

| Ká»¹ thuáº­t | Input Tokens | Output Tokens | Tá»•ng chi phÃ­ |
|----------|-------------|---------------|-------------|
| **Zero-shot** | â­ Ãt nháº¥t | Trung bÃ¬nh | ğŸ’° Ráº» nháº¥t |
| **Few-shot** | â­â­â­ Nhiá»u (cÃ³ vÃ­ dá»¥) | Ngáº¯n gá»n | ğŸ’°ğŸ’° Vá»«a pháº£i |
| **CoT** | â­â­ Vá»«a | â­â­â­ DÃ i (cÃ³ giáº£i thÃ­ch) | ğŸ’°ğŸ’°ğŸ’° Äáº¯t nháº¥t |

**Káº¿t há»£p tá»‘i Æ°u:**
```
Few-shot + CoT = Combo máº¡nh nháº¥t! (nhÆ°ng cÅ©ng Ä‘áº¯t nháº¥t)
```

**Quy táº¯c chá»n:**
- Task Ä‘Æ¡n giáº£n â†’ **Zero-shot** (tiáº¿t kiá»‡m)
- Cáº§n Ä‘Ãºng format â†’ **Few-shot** (chÃ­nh xÃ¡c)
- Cáº§n suy luáº­n â†’ **CoT** (logic)
- Task phá»©c táº¡p + cáº§n format â†’ **Few-shot + CoT** (toÃ n diá»‡n)

</details>

---

### ğŸ“Œ Thá»© 7: Ã”n táº­p Feynman

Thá»­ giáº£i thÃ­ch khÃ¡i niá»‡m "Tokenization" cho má»™t ngÆ°á»i báº¡n (hoáº·c viáº¿t blog). Náº¿u báº¡n dÃ¹ng tá»« chuyÃªn ngÃ nh quÃ¡ nhiá»u, hÃ£y Ä‘Æ¡n giáº£n hÃ³a láº¡i.

#### â“ CÃ¢u 20: HÃ£y giáº£i thÃ­ch Tokenization cho ngÆ°á»i khÃ´ng biáº¿t gÃ¬ vá» AI

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

### ğŸ• Tokenization = Cáº¯t pizza thÃ nh miáº¿ng

TÆ°á»Ÿng tÆ°á»£ng báº¡n cÃ³ má»™t cÃ¡i pizza lá»›n (= Ä‘oáº¡n vÄƒn báº£n). Báº¡n khÃ´ng thá»ƒ nhÃ©t cáº£ cÃ¡i pizza vÃ o miá»‡ng cÃ¹ng lÃºc, pháº£i **cáº¯t thÃ nh tá»«ng miáº¿ng** Ä‘á»ƒ Äƒn.

**Tokenization** cÅ©ng váº­y â€” nÃ³ **cáº¯t vÄƒn báº£n thÃ nh nhá»¯ng máº£nh nhá» (gá»i lÃ  token)** Ä‘á»ƒ mÃ¡y tÃ­nh cÃ³ thá»ƒ "Äƒn" Ä‘Æ°á»£c.

**VÃ­ dá»¥ Ä‘á»i thÆ°á»ng:**

```
CÃ¢u: "TÃ´i yÃªu Viá»‡t Nam"

Con ngÆ°á»i Ä‘á»c:  "TÃ´i" "yÃªu" "Viá»‡t" "Nam"     (4 tá»«)
MÃ¡y tÃ­nh Ä‘á»c:  "T" "Ã´i" " yÃªu" " Vi" "á»‡t" " Nam"  (6 máº£nh = 6 tokens)
```

**Táº¡i sao mÃ¡y khÃ´ng cáº¯t theo tá»« nhÆ° ngÆ°á»i?**

VÃ¬ mÃ¡y dÃ¹ng **tá»« Ä‘iá»ƒn cÃ³ sáºµn** (khoáº£ng 50,000-100,000 máº£nh). Náº¿u tá»« nÃ o cÃ³ trong tá»« Ä‘iá»ƒn â†’ giá»¯ nguyÃªn. Náº¿u khÃ´ng â†’ chia nhá» hÆ¡n.

- `"Hello"` â†’ cÃ³ trong tá»« Ä‘iá»ƒn â†’ **1 token** âœ…
- `"Xin chÃ o"` â†’ khÃ´ng cÃ³ nguyÃªn â†’ chia thÃ nh `"X"` + `"in"` + `" ch"` + `"Ã o"` = **4 tokens**

**Váº­y sao pháº£i quan tÃ¢m?**

1. **Tiá»n báº¡c:** API tÃ­nh tiá»n theo token. Tiáº¿ng Viá»‡t tá»‘n ~2-3x token so vá»›i tiáº¿ng Anh â†’ **Ä‘áº¯t hÆ¡n!**
2. **Giá»›i háº¡n:** Má»—i model cÃ³ giá»›i háº¡n token (vÃ­ dá»¥ 128,000 tokens). Viáº¿t tiáº¿ng Viá»‡t = háº¿t giá»›i háº¡n nhanh hÆ¡n.
3. **TÃ­nh toÃ¡n sai:** LLM nhÃ¬n `"12345"` thÃ nh `["123", "45"]` chá»© khÃ´ng pháº£i tá»«ng sá»‘ â†’ hay tÃ­nh sai!

**TÃ³m láº¡i:** Tokenization giá»‘ng nhÆ° cáº¯t pizza â€” cÃ¡ch cáº¯t áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡ch Äƒn (xá»­ lÃ½), giÃ¡ tiá»n, vÃ  cháº¥t lÆ°á»£ng! ğŸ•

</details>

---

## ğŸ“… TUáº¦N 3: XÃ¢y dá»±ng Bá»™ nhá»› (Memory) - "Tá»± tay lÃ m nÃªn cÆ¡m chÃ¡o"

> **Má»¥c tiÃªu:** LLM lÃ  "vÃ´ tri" (stateless). Báº¡n pháº£i táº¡o ra sá»± liÃªn káº¿t.
>
> **LÃ½ do cá»‘t lÃµi:** Má»—i láº§n báº¡n gá»i API, LLM **quÃªn sáº¡ch quÃ¡ khá»©**. Báº¡n pháº£i gá»­i láº¡i toÃ n bá»™ lá»‹ch sá»­. NhÆ°ng gá»­i bao nhiÃªu lÃ  Ä‘á»§?

### ğŸ“Œ Thá»© 2 - Thá»© 4: Cáº¥u trÃºc dá»¯ liá»‡u há»™i thoáº¡i

**TÆ° duy:** Thay vÃ¬ dÃ¹ng `LangChain.Memory`, hÃ£y dÃ¹ng `List[Dict]` cá»§a Python.

**Thá»±c hÃ nh:**
- Táº¡o má»™t `history = []`
- Má»—i láº§n User há»i â†’ `history.append({"role": "user", "content": "..."})`
- Má»—i láº§n AI tráº£ lá»i â†’ `history.append({"role": "assistant", "content": "..."})`
- Gá»­i toÃ n bá»™ `history` nÃ y lÃªn API trong láº§n gá»i tiáº¿p theo

#### â“ CÃ¢u 21: Táº¡i sao LLM khÃ´ng cÃ³ bá»™ nhá»›? Pháº£i lÃ m gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**LLM lÃ  stateless** â€” má»—i láº§n gá»i API lÃ  má»™t phiÃªn má»›i hoÃ n toÃ n, LLM khÃ´ng biáº¿t gÃ¬ vá» cuá»™c há»™i thoáº¡i trÆ°á»›c Ä‘Ã³.

**VÃ­ dá»¥ minh há»a:**
```
Láº§n gá»i 1: User: "TÃ´i tÃªn Quang"    â†’ AI: "ChÃ o Quang!"
Láº§n gá»i 2: User: "TÃ´i tÃªn gÃ¬?"      â†’ AI: "TÃ´i khÃ´ng biáº¿t tÃªn báº¡n." âŒ
```

**Giáº£i phÃ¡p:** Báº¡n pháº£i **tá»± quáº£n lÃ½ bá»™ nhá»›** báº±ng cÃ¡ch gá»­i láº¡i lá»‹ch sá»­ há»™i thoáº¡i!

```python
# Cáº¥u trÃºc dá»¯ liá»‡u há»™i thoáº¡i
history = [
    {"role": "system", "content": "Báº¡n lÃ  trá»£ lÃ½ thÃ´ng minh."},
]

# Láº§n gá»i 1
history.append({"role": "user", "content": "TÃ´i tÃªn Quang"})
response = await client.chat.completions.create(
    model=deployment,
    messages=history  # Gá»­i toÃ n bá»™ lá»‹ch sá»­
)
ai_reply = response.choices[0].message.content
history.append({"role": "assistant", "content": ai_reply})

# Láº§n gá»i 2 - LLM giá» "nhá»›" Ä‘Æ°á»£c vÃ¬ cÃ³ history!
history.append({"role": "user", "content": "TÃ´i tÃªn gÃ¬?"})
response = await client.chat.completions.create(
    model=deployment,
    messages=history  # Gá»­i lá»‹ch sá»­ bao gá»“m cáº£ láº§n gá»i 1
)
# â†’ AI: "Báº¡n tÃªn Quang!" âœ…
```

</details>

---

#### â“ CÃ¢u 22: Gá»­i toÃ n bá»™ history cÃ³ váº¥n Ä‘á» gÃ¬?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**3 váº¥n Ä‘á» chÃ­nh khi history quÃ¡ dÃ i:**

| Váº¥n Ä‘á» | Chi tiáº¿t |
|--------|---------|
| ğŸ’° **Chi phÃ­ tÄƒng** | Má»—i láº§n gá»i API Ä‘á»u gá»­i toÃ n bá»™ history â†’ sá»‘ token tÄƒng dáº§n â†’ tiá»n tÄƒng theo! |
| ğŸš« **VÆ°á»£t Context Window** | GPT-4o giá»›i háº¡n ~128K tokens. History dÃ i quÃ¡ â†’ lá»—i! |
| ğŸŒ **Response cháº­m hÆ¡n** | Input dÃ i â†’ LLM xá»­ lÃ½ lÃ¢u hÆ¡n |

**Giáº£i phÃ¡p thá»±c táº¿:**

```python
def manage_history(history, max_messages=20):
    """
    Giá»¯ history trong giá»›i háº¡n.
    - LuÃ´n giá»¯ system message (index 0)
    - Chá»‰ giá»¯ N tin nháº¯n cuá»‘i cÃ¹ng
    """
    if len(history) <= max_messages:
        return history
    
    # Giá»¯ system message + N tin nháº¯n cuá»‘i
    return [history[0]] + history[-(max_messages - 1):]
```

**CÃ¡c chiáº¿n lÆ°á»£c nÃ¢ng cao:**
1. **Sliding Window:** Giá»¯ N tin nháº¯n gáº§n nháº¥t (Ä‘Æ¡n giáº£n nháº¥t)
2. **Summarization:** DÃ¹ng LLM tÃ³m táº¯t history cÅ© thÃ nh 1 message
3. **Token-based:** Äáº¿m token vÃ  cáº¯t khi vÆ°á»£t giá»›i háº¡n (dÃ¹ng `truncate_text` tá»« Tuáº§n 2!)

**ğŸ’¡ ÄÃ¢y chÃ­nh lÃ  lÃ½ do ká»¹ nÄƒng `truncate_text` á»Ÿ Tuáº§n 2 quan trá»ng!**

</details>

---

#### â“ CÃ¢u 23: Cáº¥u trÃºc messages gá»­i lÃªn API gá»“m nhá»¯ng role nÃ o?

<details>
<summary>ğŸ‘‰ Xem Ä‘Ã¡p Ã¡n</summary>

**3 role chÃ­nh trong messages:**

| Role | Ã nghÄ©a | VÃ­ dá»¥ |
|------|---------|-------|
| `system` | **Thiáº¿t láº­p nhÃ¢n cÃ¡ch & quy táº¯c** cho LLM. Chá»‰ dÃ¹ng 1 láº§n á»Ÿ Ä‘áº§u. | `"Báº¡n lÃ  trá»£ lÃ½ dá»‹ch thuáº­t Anh-Viá»‡t."` |
| `user` | **Tin nháº¯n tá»« ngÆ°á»i dÃ¹ng** | `"Dá»‹ch: Hello World"` |
| `assistant` | **CÃ¢u tráº£ lá»i tá»« LLM** (history cÅ© hoáº·c few-shot examples) | `"Xin chÃ o Tháº¿ giá»›i"` |

**Cáº¥u trÃºc hoÃ n chá»‰nh:**
```python
messages = [
    # System: "Linh há»“n" cá»§a chatbot
    {"role": "system", "content": "Báº¡n lÃ  trá»£ lÃ½ AI thÃ¢n thiá»‡n, tráº£ lá»i ngáº¯n gá»n."},
    
    # Lá»‹ch sá»­ há»™i thoáº¡i (do báº¡n tá»± quáº£n lÃ½)
    {"role": "user",      "content": "Xin chÃ o!"},
    {"role": "assistant", "content": "ChÃ o báº¡n! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬?"},
    
    # CÃ¢u há»i hiá»‡n táº¡i
    {"role": "user",      "content": "Giáº£i thÃ­ch AI trong 1 cÃ¢u."},
]
```

**ğŸ’¡ Ghi nhá»›:**
- `system` â†’ Ä‘áº·t má»™t láº§n, áº£nh hÆ°á»Ÿng toÃ n bá»™ cuá»™c trÃ² chuyá»‡n
- `user` + `assistant` â†’ xen káº½ táº¡o thÃ nh lá»‹ch sá»­ há»™i thoáº¡i
- Thá»© tá»± ráº¥t quan trá»ng â†’ LLM Ä‘á»c tá»« trÃªn xuá»‘ng dÆ°á»›i!

</details>

---

## ğŸ“ Files trong project

| File | MÃ´ táº£ | Tuáº§n |
|------|-------|------|
| `hello_llm.py` | Demo gá»i Azure OpenAI cÆ¡ báº£n (sync) - "PhÃ¡ vá»¡ há»™p Ä‘en" JSON response | Tuáº§n 1 |
| `async_llm.py` | Demo gá»i Azure OpenAI báº¥t Ä‘á»“ng bá»™ (async) vá»›i `asyncio.gather()` | Tuáº§n 1 |
| `token_kung_fu.py` | Demo tokenization - cÃ¡ch LLM "nhÃ¬n" vÄƒn báº£n, tÃ­nh chi phÃ­ | Tuáº§n 2 |
| `prompt_engineering.py` | Demo 3 ká»¹ thuáº­t prompting: Zero-shot, Few-shot, CoT | Tuáº§n 2 |
| `prompt_engineering_log.txt` | Log output tá»« `prompt_engineering.py` | Tuáº§n 2 |
| `list_models.py` | Liá»‡t kÃª cÃ¡c models cÃ³ sáºµn trÃªn Azure OpenAI | - |
| `models.txt` | Danh sÃ¡ch models Ä‘Ã£ liá»‡t kÃª | - |

---

## ğŸ”§ Cáº¥u hÃ¬nh

Táº¡o file `.env` vá»›i cÃ¡c biáº¿n:
```
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_DEPLOYMENT=your_deployment_name
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

---

## ğŸ“š CÃ i Ä‘áº·t thÆ° viá»‡n

```bash
pip install openai python-dotenv tiktoken tenacity aiohttp
```
